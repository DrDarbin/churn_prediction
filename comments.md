### Что можно сделать ещё при наличии базы?
1. Проверить независимые переменные на значимость (t-test) и отбросить лишнее/добавить новые переменные. Проверить F-test, R^2 adjusted на общую занчимость прогностической способности модели.
2. Проверить переменные на мультиколлинеарность (корреляционная матрица) и избавиться от неё (удалив кореллирующие переменные)
3. Проверить модель на гетероскедастичность (White test) и посмотреть можно ли улучшить модель
4. Проверить модель на автокорелляцию и избавиться от неё при наличии (Darbin Watson test; но это не должно быть кейсом для текущих даных)
5. Расширить модель новыми производными переменными на базе фактороного анализа (PCA) (в т.ч. может быть полезным при избавлении от мультиколлинеарности)
6. Features engineering:
	* Использовать NER (Named Entity Recognition) техники для классификаци текстового Course_description
	* Определить пол студента по фамилии ('ова', 'ов' и т.п.)
	* Динамика показателей во времени (курсы стареют например, становятся неактуальными и отток с них может со временем регистрровтаься всё больше)
	* При наличии id курса: ['Course_communicativeness'] = сумма ['Student_MessagesQnt'] для данного курса (отражает интерес слушателей к курсу в целом)
	* Другие производные (частное/суммы/произведения полей и т.п.)

### Дополнительные возможности рефакторинга:
1. Переписать всё через piplines для удобства экспериментирования
2. Покрыть код тестами с помощью Unittest, если планируются эксперименты и дальнейшее усложнение/интеграция модели

### Развитие модели:
1. Для улучшения модели имеет смысл использовать Light GBM / XGBoost - они обычно дают более сильный прогностически результат за счёт бустинга. Logit чаще используется для анализа и понимания модели, значимости независимых переменных и т.п.
2. Также можно попробовать TensorFlow + Keras или PyTorch - хорошая конкуренция Light GBM / XGBoost.